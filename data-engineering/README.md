<div align="center">
  <img src="https://anthropos.work/_next/image?url=https%3A%2F%2Fcontent.anthropos.work%2Fassets%2Ff6e18932-35b9-4d8f-9cb5-cb22e84be577&w=3840&q=90" alt="Data Engineering Header" width="100%" style="max-width: 800px;" />
</div>

# ‚öôÔ∏è Data Engineering

This section showcases my data engineering projects and expertise. Here, I demonstrate end-to-end data pipeline workflows covering:

## Key Areas

- **ETL/ELT Pipeline Development**: Building scalable data ingestion and transformation pipelines
- **Medallion Architecture**: Implementing Bronze ‚Üí Silver ‚Üí Gold data lakehouse patterns
- **Big Data Technologies**: Working with Apache Spark, Delta Lake, and Databricks
- **Workflow Orchestration**: Automating complex data workflows with dependency management
- **Data Quality & Governance**: Enforcing schema validation, data quality checks, and access controls
- **Cloud Infrastructure**: Deploying pipelines on AWS S3, Databricks, and Unity Catalog

## Projects

Each project demonstrates practical application of modern data engineering techniques, from raw data ingestion to analytics-ready tables ready for business intelligence and machine learning.

---

### üèÜ Featured: Factored Datathon 2024 - Overall Grand Winner

The GDELT Big Data Engineering project was developed as part of our award-winning solution at Factored Datathon 2024, where we implemented a production-ready data lakehouse architecture processing billions of global news records for maritime port disruption prediction.

---
